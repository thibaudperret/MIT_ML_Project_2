{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "from helpers import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading of the training images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 800 satellite images\n",
      "Loading 800 groundtruth images\n",
      "Image size = 400,400\n"
     ]
    }
   ],
   "source": [
    "# Loaded a set of images\n",
    "\n",
    "root_dir = \"augmented_training/\"\n",
    "#root_dir = \"training/\"\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)  \n",
    "\n",
    "n = 800\n",
    "\n",
    "print(\"Loading \" + str(n) + \" satellite images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)] #List of each image Dim (100, 400,400,3)\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "files2 = os.listdir(gt_dir)\n",
    "\n",
    "print(\"Loading \" + str(n) + \" groundtruth images\")\n",
    "gt_imgs = [load_image(gt_dir + files2[i]) for i in range(n)]\n",
    "print('Image size = ' + str(imgs[0].shape[0]) + ',' + str(imgs[0].shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract patches from input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_patches:(500000, 16, 16, 3)\n",
      "gt_patches:(500000, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "patch_size = 16 # each patch is 16*16 pixels  #400/16 = 25*25 = 625 patches for 10 images\n",
    "\n",
    "img_patches = [img_crop(imgs[i], patch_size, patch_size) for i in range(n)]   # dim img_patches = (n,625,16,16,3)\n",
    "gt_patches = [img_crop(gt_imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "\n",
    "# Linearize list of patches\n",
    "\n",
    "img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "\n",
    "print(\"img_patches:\" + str(img_patches.shape))\n",
    "print(\"gt_patches:\" + str(gt_patches.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building of the Dataset & Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_X_Y_classes(img_patches,gt_patches,foreground_threshold):\n",
    "    \n",
    "    X = np.asarray([extract_features(img_patches[i]) for i in range(len(img_patches))])\n",
    "    Y = np.asarray([value_to_class(np.mean(gt_patches[i]),foreground_threshold) for i in range(len(gt_patches))])\n",
    "    \n",
    "    return X,Y\n",
    "\n",
    "def build_poly(X,n):\n",
    "    \n",
    "    poly = PolynomialFeatures(n, interaction_only=False) #Including interaction \n",
    "    return poly.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def logistic_regression_test(degree):\n",
    "    \n",
    "        foreground_threshold = 0.25\n",
    "        t1 = datetime.datetime.now()\n",
    "        X,Y = build_X_Y_classes(img_patches,gt_patches,foreground_threshold) \n",
    "        t2 = datetime.datetime.now()\n",
    "        \n",
    "        print(\"Build classes time: \",t2 - t1)\n",
    "        \n",
    "        tX = build_poly(X,degree)\n",
    "        logreg = linear_model.LogisticRegression(C=1e5, class_weight=\"balanced\",max_iter = 100)\n",
    "    \n",
    "        t3 = datetime.datetime.now()\n",
    "        logreg.fit(tX,Y)\n",
    "        t4 = datetime.datetime.now()\n",
    "        \n",
    "        print(\"Log_reg time: \", t4 - t3)\n",
    "        \n",
    "    # Predict on the training set\n",
    "        Z = logreg.predict(tX)\n",
    "\n",
    "        ratio = f1_score(Y,Z, average = 'macro')\n",
    "        \n",
    "        weight = logreg.coef_\n",
    "        print('Ratio = ' + str(ratio))\n",
    "\n",
    "        return ratio, weight \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for different degrees of polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1\n",
      "\n",
      "Build classes time:  0:02:01.227545\n",
      "Log_reg time:  0:00:02.349471\n",
      "Ratio = 0.563814672431\n",
      "Degree 2\n",
      "\n",
      "Build classes time:  0:01:40.117842\n",
      "Log_reg time:  0:00:36.721641\n",
      "Ratio = 0.673430983951\n",
      "Degree 3\n",
      "\n",
      "Build classes time:  0:01:33.606131\n",
      "Log_reg time:  0:03:19.439735\n",
      "Ratio = 0.681667190235\n",
      "Degree 4\n",
      "\n",
      "Build classes time:  0:01:39.028671\n",
      "Log_reg time:  0:09:56.862041\n",
      "Ratio = 0.68325067749\n",
      "\n",
      "Max ratio 0.6832506774902665 at degree 4\n"
     ]
    }
   ],
   "source": [
    "ratios = []\n",
    "weights = []\n",
    "degrees = range(1,5)\n",
    "\n",
    "for n in degrees:\n",
    "    print(\"Degree {}\\n\".format(n))\n",
    "          \n",
    "    ratio, weight = logistic_regression_test(n)\n",
    "          \n",
    "    ratios.append(ratio)\n",
    "    weights.append(weight)\n",
    "    \n",
    "print(\"\\nMax ratio {a} at degree {b}\".format(a = max(ratios) , b = ratios.index(max(ratios)) + 1)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.04955372e+00  -9.07297527e+01  -3.02127799e+01   8.45424605e+01\n",
      "   -5.41809764e+02   2.91029357e+02   2.61706893e+02  -1.78574225e+03\n",
      "    3.55108864e+03   1.31629292e+03  -6.20545435e+02  -3.10291818e+02\n",
      "   -2.24847120e+02  -8.59320248e+02  -1.59502228e+03  -3.03466442e+03\n",
      "    2.15429481e+03   1.51091401e+03  -5.01294986e+02   7.10277671e+03\n",
      "   -3.74962966e+03  -2.71105667e+03   1.42396738e+03  -1.63715837e+03\n",
      "    2.17416004e+03  -2.90679285e+03  -7.21907063e+02   3.65997876e+02\n",
      "   -1.03605633e+03  -4.58478218e+03   2.41682169e+03   1.27839663e+03\n",
      "    1.62138701e+03  -3.67245674e+02   1.09500416e+02   3.51478180e+03\n",
      "   -1.85861828e+03  -3.49670397e+02  -9.72902161e+02   2.71235591e+03\n",
      "   -4.45912857e+02  -1.21701377e+03  -1.36683140e+03  -1.48911888e+03\n",
      "   -7.30415294e+02  -2.18105489e+02   3.23529535e+02   1.63852951e+02\n",
      "   -5.41040945e+02  -1.39541592e+00  -5.37332467e+02  -1.67955778e+03\n",
      "    1.02814419e+03   1.19033038e+03   3.89933571e+02  -5.13589818e+02\n",
      "   -3.82845517e+02   6.01918817e+02  -3.02077216e+02   4.79672875e+02\n",
      "    9.56849303e+02   1.50228010e+03   1.37586733e+03   6.76917076e+02\n",
      "   -3.16880358e+03   1.15522898e+03   3.68921135e+02   1.52571255e+03\n",
      "   -7.88662171e+02   7.03198641e+01   3.73917682e+02   1.16342484e+03\n",
      "    9.42717709e+02   1.93794965e+02   9.18169810e+02   8.23594206e+02\n",
      "    3.89022282e+02   7.97257279e+02   2.91397948e+02  -2.81636100e+02\n",
      "    8.11161094e+02   2.45772950e+02  -3.72135546e+02  -1.07602171e+03\n",
      "    3.62902992e+03  -1.12221373e+03  -1.38521124e+03   2.49401445e+03\n",
      "    2.04814028e+03  -1.44895657e+02  -4.90117974e+02  -1.05954333e+03\n",
      "    3.78025546e+02   4.06590895e+02  -8.46880988e+02  -2.27051367e+03\n",
      "   -9.86999960e+01  -1.26736688e+01  -8.62936423e+02  -1.10899398e+03\n",
      "   -3.38925551e+02  -6.08350449e+02   3.65449330e+02  -1.71891660e+02\n",
      "   -9.82110720e+02   1.23830074e+03  -2.52855269e+01  -5.53231839e+02\n",
      "   -4.82011595e+01  -5.45948511e+02  -5.44421436e+02  -9.57693755e+02\n",
      "   -4.32710807e+02  -5.01076340e+02  -7.40538872e+02   3.83251160e+01\n",
      "   -2.37732207e+02   7.43265188e+02   2.26103874e+02  -5.70663428e+02\n",
      "   -1.13881840e+03  -1.10654027e+03  -2.57888650e+02  -3.61459029e+01\n",
      "   -9.92125734e+02  -1.93088468e+02  -4.82719139e+02   5.34794984e+02\n",
      "    3.23513588e+01  -7.32602185e+02   1.34666837e+02   2.08025246e+02\n",
      "   -8.13165518e+01   2.79192894e+02  -4.38035882e+01  -4.00696770e+02\n",
      "    3.39286444e+02  -1.28598000e+01  -3.91669307e+02  -8.07557055e+02\n",
      "    1.24490379e+03  -7.97291332e+02  -5.76779054e+02   4.60525083e+02\n",
      "    5.72091235e+02  -4.31723195e+02  -1.04297091e+03  -2.77477242e+01\n",
      "    5.80652088e+02  -3.07512613e+02   4.69119530e+02   1.73840728e+02\n",
      "    1.17459142e+03   6.68558939e+02  -1.20184073e+02   7.90126902e+02\n",
      "   -1.19981622e+03   1.31552516e+02   1.08120171e+03  -6.12904805e+02\n",
      "    1.83590517e+02  -1.25080551e+02   9.16127689e+02   4.25060535e+02\n",
      "   -3.24458041e+02   1.72120775e+02   2.48104755e+02  -4.89348422e+01\n",
      "    3.19520046e+02  -9.33373981e+00  -3.74158102e+02   3.79621496e+02\n",
      "    2.43189873e+01  -3.58884392e+02  -7.79171922e+02   2.43019984e+03\n",
      "   -1.16397621e+03   7.03763482e+02   1.91965403e+03  -8.52665841e+02\n",
      "   -3.24730145e+01  -3.67465058e+02   7.29159855e+02   2.41647877e+02\n",
      "   -4.74698319e+02  -1.22939143e+01   7.63245051e+01  -2.12318830e+02\n",
      "    1.58404701e+02  -1.61315579e+02  -5.17353997e+02   2.28337867e+02\n",
      "   -1.16757273e+02  -4.89246892e+02  -8.94481708e+02  -1.35030561e+02\n",
      "   -1.32436724e+02  -2.38134260e+02  -1.28129866e+02  -2.37601024e+02\n",
      "   -3.48641610e+02  -1.23745964e+02  -2.37105723e+02  -3.51541357e+02\n",
      "   -4.69900185e+02  -1.20512542e+02  -2.37755072e+02  -3.55414841e+02\n",
      "   -4.75818065e+02  -6.00334602e+02]]\n"
     ]
    }
   ],
   "source": [
    "max_index = ratios.index(max(ratios))\n",
    "weight = weights[max_index]\n",
    "\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of Test Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 50 test images\n",
      "Size of image: 608,608\n"
     ]
    }
   ],
   "source": [
    "test_dir = 'test_set_images/'\n",
    "imgs = load_test_images(test_dir) ##In helpers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building of the Test dataset + polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_patches:(72200, 16, 16, 3)\n",
      "Dataset (RGB features Mean/Variance) : (72200, 6)\n"
     ]
    }
   ],
   "source": [
    "patch_size = 16 # each patch is 16*16 pixels  #400/16 = 25*25 = 625 patches for 10 images\n",
    "\n",
    "img_patches = [img_crop(imgs[i], patch_size, patch_size) for i in range(len(imgs))]# dim img_patches\n",
    "img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "\n",
    "print(\"img_patches:\" + str(img_patches.shape))\n",
    "\n",
    "data = np.asarray([extract_features(img_patches[i]) for i in range(len(img_patches))])\n",
    "print('Dataset (RGB features Mean/Variance) :', data.shape)\n",
    "\n",
    "t_data = build_poly(data,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_shape: before (72200, 1)\n",
      "prediction_shape: after (50, 1444)\n"
     ]
    }
   ],
   "source": [
    "y_pred = t_data @ weight.T\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] < 0.5:\n",
    "        y_pred[i] = 0\n",
    "    else:\n",
    "        y_pred[i] = 1\n",
    "\n",
    "print('prediction_shape: before',y_pred.shape)\n",
    "labels = np.reshape(y_pred,(50,1444))\n",
    "print('prediction_shape: after',labels.shape) ##iterate over each image more easily\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgwidth = imgs[0].shape[0] \n",
    "imgheight = imgs[0].shape[1] \n",
    "w = patch_size\n",
    "h = patch_size\n",
    "\n",
    "os.makedirs('prediction_test_logistic/', exist_ok=True) \n",
    "\n",
    "for i in range(len(labels)):\n",
    "    im = label_to_img(imgwidth, imgheight, w, h, labels[i])\n",
    "    im = img_float_to_uint8(im)\n",
    "    Image.fromarray(im).save('prediction_test_logistic/prediction_' + '%.3d' % (i + 1)+ '.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask to submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'RUN mask_to_submission.py with the right path to test prediction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch_size = 16\n",
    "\n",
    "def extract_img_features(filename):\n",
    "    img = load_image(filename)\n",
    "    img_patches = img_crop(img, patch_size, patch_size)\n",
    "    X = np.asarray([ extract_features(img_patches[i]) for i in range(len(img_patches))])\n",
    "    return X\n",
    "\n",
    "# Run prediction on the img_idx-th image\n",
    "img_idx = 12\n",
    "\n",
    "Xi = extract_img_features(image_dir + files[img_idx])\n",
    "tXi = build_poly(Xi,3)\n",
    "Zi = logreg.predict(tXi)\n",
    "print(Zi.shape)\n",
    "plt.scatter(Xi[:, 0], Xi[:, 4], c=Zi, edgecolors='k', cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = gt_imgs[img_idx].shape[0]\n",
    "h = gt_imgs[img_idx].shape[1]\n",
    "predicted_im = label_to_img(w, h, patch_size, patch_size, Zi)\n",
    "cimg = concatenate_images(imgs[img_idx], predicted_im)\n",
    "fig1 = plt.figure(figsize=(10, 10)) # create a figure with the default size \n",
    "plt.imshow(cimg, cmap='Greys_r')\n",
    "\n",
    "new_img = make_img_overlay(imgs[img_idx], predicted_im)\n",
    "\n",
    "plt.imshow(new_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot features using predictions to color datapoints\n",
    "plt.scatter(X[:, 0], X[:, 4], c=Z, edgecolors='k', cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot 2d features using groundtruth to color the datapoints\n",
    "\n",
    "subplot(1,3,1)\n",
    "subplots_adjust(left=None, bottom=None, right=2, top=None, wspace=None, hspace=None)\n",
    "plt.scatter(X[:, 0], X[:, 3], c=Y, edgecolors='k', cmap=plt.cm.Paired) #c is the color  #orange dot = class 1 = foreground\n",
    "plt.title(\"Red\")\n",
    "subplot(1,3,2)\n",
    "plt.scatter(X[:, 1], X[:, 4], c=Y, edgecolors='k', cmap=plt.cm.Paired) #c is the color  #orange dot = class 1 = foreground\n",
    "plt.title(\"Green\")\n",
    "subplot(1,3,3)\n",
    "plt.scatter(X[:, 2], X[:, 5], c=Y, edgecolors='k', cmap=plt.cm.Paired) #c is the color  #orange dot = class 1 = foreground\n",
    "plt.title(\"Blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(gt_patches[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extract_features(img_patches[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(1,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-41389fad42b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
